---
title: "PS2_template"
output: html_document
author: Kaden Coulter
date: "2025-04-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# RNA-seq Quality Assessment Assignment - Bi 623 (Summer 2025 Assignment/PS 2)

## Overall assignment:

In this assignment, you will process electric organ and/or skeletal muscle RNA-seq reads for a future differential gene expression analysis. We will be completing the differential gene expression analysis in our last bioinformatics assignment of this class. You will learn how to use existing tools for quality assessment and read trimming, compare quality assessments to those created by your own software, and how to align and count reads. Additionally, you will learn how to summarize important information in a high-level report. You should create a cohesive, well written report for your "PI" about what you've learned about/from your data.

**This template is provided as reference for instructions. Files with specific naming conventions are requested to be turned in at the end of this problem set. You can use this template to gather notes while completing this assignment.** Be sure to upload all relevant materials by the deadline and **double check** to be sure that your offline repository is up-to-date with your online repository. Answers to questions should be included in your final, high-level, report as a `pdf`. This pdf should be generated using Rmarkdown and submitted to Canvas as well as GitHub. Be sure to keep a well-organized, detailed lab notebook!

### Dataset:

Each of you will be working with 2 RNA-seq files from two different electric fish studies (PRJNA1005245 and PRJNA1005244). The methods for the PRJNA1005244 dataset are [published](https://doi.org/10.1093/molbev/msae021) and the methods for the PRJNA1005245 dataset are written in the third chapter of a [thesis](https://canvas.uoregon.edu/courses/266187/files/22059308?module_item_id=5380118). For all steps below, process the two libraries separately. SRR assignments are here: `/projects/bgmp/shared/Bi623/PS2/QAA_data_Assignments.txt`. If you have time, consider claiming and processing additional RNA-seq raw sequencing files via this [google doc](https://docs.google.com/document/d/1vEmVEzUaTjbDF4JyNsWH-wFpi8dm4wkcvWgSoYZzoCY/edit?usp=sharing). Although this is not extra credit, it will make our downstream RNA-seq analysis more interesting and your classmates will appreciate your efforts.

SRR25630309 and SRR25630393 are the Files that I am assigned.

You are responsible for downloading this data from NCBI SRA, dumping into FASTQ files, and zipping those files (check ICA1 for a refresher). We are processing this data for use in a future assignment, so please keep your files well organized. Finally, rename the files to the convention Species_sample_tissue_age/size_sample#\_readnumber.fastq.gz.

**Reminder: This template file IS not your final product; however, it gives you a space to record all of the necessary information for your final report.**

```{bash, eval=FALSE}
## Download your data
$ prefetch SRR25630309
$ prefetch SRR25630393
$ fasterq-dump SRR25630393 --split-files --progress
$ fasterq-dump SRR25630309 --split-files --progress
$ mv SRR25630309_1.fastq Cco_com123_EO_6cm_1_1.fastq
$ mv SRR25630309_2.fastq Cco_com123_EO_6cm_1_2.fastq
$ mv SRR25630393_1.fastq Crh_rhy116_EO_adult_3_1.fastq
$ mv SRR25630393_2.fastq Crh_rhy116_EO_adult_3_2.fastq
$ gzip Cco_com123_EO_6cm_1_1.fastq
$ gzip Cco_com123_EO_6cm_1_2.fastq
$ gzip Crh_rhy116_EO_adult_3_1.fastq
$ gzip Crh_rhy116_EO_adult_3_2.fastq
```

## Part 1 â€“ Read quality score distributions

1.  Create a new conda environment called `QAA` and install `FastQC`, `cutadapt`, and `Trimmomatic`. Google around if you need a refresher on how to create conda environments. Recommend doing this in an interactive session, not the login node! Record details of how you created this environment in your lab notebook! Make sure you check your installation with:
    -   `fastqc --version` (should be 0.12.1)

[Record details on how you made the conda environment]

```{bash, eval=FALSE}
$ conda create -n QAA
$ mamba activate QAA
$ mamba install FastQC
$ mamba install cutadapt
$ mamba install Trimmomatic
$ fastqc --version
```

2.  Using `FastQC` via the command line on Talapas, produce plots of the per-base quality score distributions for R1 and R2 reads. Also, produce plots of the per-base N content, and comment on whether or not they are consistent with the quality score plots.

[Include FastQC commands, plots of per-base N content, comments on consistency with quality score plots]

```{bash, eval=FALSE}
$ fastqc *.gz
$ open Cco_com123_EO_6cm_1_1_fastqc.html
$ open Cco_com123_EO_6cm_1_2_fastqc.html
$ open Crh_rhy116_EO_adult_3_1_fastqc.html
$ open Crh_rhy116_EO_adult_3_2_fastqc.html 
```

-   Cco_com123_EO_6cm_1_1_fastqc.html

    For the Cco_com123_EO_6cm_1_1 per-base quality score distribution, we see consistent quality scores across all bases. There is some slight improvement from 1-3 bp and then an extremely gradual decline through 150, with a quality score greater than or equal to 34. The per-base N content is also seemingly fantastic. Through all positions, 0% N content is maintained. That is, through all bases we have no N content. We can see clear consistency with the quality score plots.

-   Cco_com123_EO_6cm_1_2_fastqc.html

    For the Cco_com123_EO_6cm_1_2 per-base quality score distribution, we see less consistent, but still great quality scores. We see a gradual decline from bp 1 through bp 150, dropping from 36 to what appears to be a Quality score of 33. In the per-base N content plot, we can, again, see 0% N content through all bases. We can see clear consistency with the quality score plots.

-   Crh_rhy116_EO_adult_3_1_fastqc.html

    For the Crh_rhy116_EO_adult_3_1 per-base quality score distribution, we, once again, see consistent quality scores across all bases.There is some slight improvement from 1-5 bp followed by an extremely gradual decline through bp 150, with quality scores in the 34-36 range. When examining the per-base N content, we, again, see 0% N content through all bases and maintain consistency with the quality score plots.

-   Crh_rhy116_EO_adult_3_2_fastqc.html

    For the Crh_rhy116_EO_adult_3_2_fastqc, we, once again, see a consistent quality score of 34-36 across all bp in the per-base quality score distribution. Once again, is a very gradual decline over bp in the quality score. Again, we see a per-base N content consistent with our quality scores. However, we see a small spike at bp1, seemingly demonstrating a 1% N Content at bp1. Even so, this is consistent with the other plot.

3.  Run your quality score plotting script from your Demultiplexing assignment in Bi622. (Make sure you're using the "running sum" strategy!!) Describe how the `FastQC` quality score distribution plots compare to your own. If different, propose an explanation. Also, does the run time differ? Mem/CPU usage? If so, why?

```{r, eval=FALSE}
$ gzip -dc Cco_com123_EO_6cm_1_1.fastq.gz | head -n 4 | awk '{ print length($0) }'
```

    The plots look nearly identical (as far as values), but my process was faster than the entire FastQC output. I did not use a quality score cutoff, include error bars, or bin the quality scores into acceptable and less acceptable regions, but beyond that, my output matches the FastQC. 
    
While the runtime was shorter, my process may not be as fast or resource efficient as FastQC. 
    
    First, my script is written in Python, which is much slower than the languages FASTQC is likely written in, such as Java or C. Also, my script is optimized for logic and readability, whereas FASTQC is undoubtedly optimized for speed and resource efficiency. Finally, I am creating a single plot, not multiple, formatting them into an html, or producing detailed user messages and warnings like FastQC. While other factors also contribute to the high memory usage, CPU load, and runtime of my script, these are the primary reasons it may not be faster than FastQC, like it seems. 

INSERT CCo_1.png !!! 

4.  Comment on the overall data quality of your two libraries. Go beyond per-base qscore distributions. Examine the `FastQC` [documentation](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/) for guidance on interpreting results and planning next steps. Make and justify a recommendation on whether these data are of high enough quality to use for further analysis.

[Include comments on data quality and recommendation on whether this can be used for further analysis]

-   Per Tile Sequence Quality: !

    In Cco_com123_EO_6cm_1_1, we see a bit of decline in quality per tile as we reach the end of our reads. However, this is very minor, and displays no effect on the read quality in any of the other measures. In our sequence quality plots, at these base positions, we see more variance in the quality score, but a more than acceptable score. So, there is nothing to worry about in this warning.

-   Per Base Sequence Content: X

    In all files, we see Per base sequence content flagged as failure. However, this is just our bar codes at the beginning of the reads. This warning can be dismissed.

-   Per Sequence GC content: !

    In Cco_com123_EO_6cm_1_1, GC content is sightly left skewed from the normal distribution that is expected. However, we still create a normal distribution that is only *slightly* offset from what is expected. We see a bit of noise in the peak, but, again, this is not something to be overly concerned with and this warning can be dismissed.

-   Sequence Duplication Levels: X

    In every file we get Sequence Duplication Levels flagged as failure. However, this is expected in RNA-seq, which we have here. Due to highly expressed transcripts, paired end reads in our sequencing process, and fragment size bias, this can be expected. We can dismiss this warning.

-   Adapter Content: X

    In every file, we get an adapter content warning flagged as failure. Again, this is an artifact or leftover of RNA-seq and can be dismissed. We have short fragments, causing us to sequence the adapter at the end of our reads. We have a bit of contamination at the end of our reads, suggesting our adapters are a bit long. This is expected in illumina RNA-seq and can be dismissed.

-   CAN WE USE THESE FILES FOR FURTHER ANALYSIS:

    Based on the data quality and the dismissal of all raised warnings, we can continue to analyze this data. Everything looks as expected for the type of sequencing we used to generate this data, the data is high quality, and nothing seems questionable or suspicious. Continue with analysis!

## Part 2 â€“ Adaptor trimming comparison

5.  If you haven't already in your QAA environment, install `Cutadapt` and `Trimmomatic`. Check your installations with:
    -   `cutadapt --version` (should be 5.0)
    -   `trimmomatic -version` (should be 0.39)

[Record details on install (if happened here) and/or version checking]

```{bash, eval=FALSE}
$ cutadapt --version
## 5.1
$ trimmomatic -version
## 0.40
```

6.  Using `Cutadapt`, properly trim adapter sequences from your assigned files. Be sure to read how to use `Cutadapt`. Use default settings. What proportion of reads (both R1 and R2) were trimmed?

-   We are using Illumina TruSeq adapters -\> verified after vy looking at the hint.

```{bash, eval=FALSE}
cutadapt \
-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \
-A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \
-o Cco_com123_EO_6cm_1_1_cut.fastq.gz \
-p Cco_com123_EO_6cm_1_2_cut.fastq.gz \
Cco_com123_EO_6cm_1_1.fastq.gz Cco_com123_EO_6cm_1_2.fastq.gz
```

``` {eval="FALSE"}
Done           00:00:39     3,735,980 reads @  10.6 Âµs/read;   5.67 M reads/minute

=== Summary ===

Total read pairs processed:          3,735,980
  Read 1 with adapter:                 589,610 (15.8%)
  Read 2 with adapter:                 610,016 (16.3%)
Pairs written (passing filters):     3,735,980 (100.0%)

Total basepairs processed: 1,120,794,000 bp
  Read 1:   560,397,000 bp
  Read 2:   560,397,000 bp
Total written (filtered):  1,094,083,321 bp (97.6%)
  Read 1:   546,818,038 bp
  Read 2:   547,265,283 bp

=== First read: Adapter 1 ===

Sequence: AGATCGGAAGAGCACACGTCTGAACTCCAGTCA; Type: regular 3'; Length: 33; Trimmed: 589610 times

Minimum overlap: 3
No. of allowed errors:
1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-33 bp: 3

Bases preceding removed adapters:
  A: 11.1%
  C: 26.7%
  G: 47.2%
  T: 15.0%
  none/other: 0.0%

=== Second read: Adapter 2 ===

Sequence: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT; Type: regular 3'; Length: 33; Trimmed: 610016 times

Minimum overlap: 3
No. of allowed errors:
1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-33 bp: 3

Bases preceding removed adapters:
  A: 9.3%
  C: 21.8%
  G: 58.4%
  T: 10.5%
  none/other: 0.0%
```

```{bash, eval=FALSE}
cutadapt \
-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \
-A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \
-o Crh_rhy116_EO_adult_3_1_cut.fastq.gz \
-p Crh_rhy116_EO_adult_3_2_cut.fastq.gz \
Crh_rhy116_EO_adult_3_1.fastq.gz Crh_rhy116_EO_adult_3_2.fastq.gz
```

``` {eval="FALSE"}
Done           00:05:29    32,594,028 reads @  10.1 Âµs/read;   5.94 M reads/minute

=== Summary ===

Total read pairs processed:         32,594,028
  Read 1 with adapter:               4,264,287 (13.1%)
  Read 2 with adapter:               4,455,966 (13.7%)
Pairs written (passing filters):    32,594,028 (100.0%)

Total basepairs processed: 9,778,208,400 bp
  Read 1: 4,889,104,200 bp
  Read 2: 4,889,104,200 bp
Total written (filtered):  9,593,951,183 bp (98.1%)
  Read 1: 4,795,698,545 bp
  Read 2: 4,798,252,638 bp

=== First read: Adapter 1 ===

Sequence: AGATCGGAAGAGCACACGTCTGAACTCCAGTCA; Type: regular 3'; Length: 33; Trimmed: 4264287 times

Minimum overlap: 3
No. of allowed errors:
1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-33 bp: 3

Bases preceding removed adapters:
  A: 11.9%
  C: 25.1%
  G: 48.4%
  T: 14.6%
  none/other: 0.0%
  
=== Second read: Adapter 2 ===

Sequence: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT; Type: regular 3'; Length: 33; Trimmed: 4455966 times

Minimum overlap: 3
No. of allowed errors:
1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-33 bp: 3

Bases preceding removed adapters:
  A: 10.7%
  C: 24.8%
  G: 53.6%
  T: 10.9%
  none/other: 0.0%
```

<details>

<summary>Try to determine what the adapters are on your own. If you cannot (or if you do, and want to confirm), click here to see the actual adapter sequences used.</summary>

R1: `AGATCGGAAGAGCACACGTCTGAACTCCAGTCA`

R2: `AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT`

</details>

-   *Sanity check*: Use your Unix skills to search for the adapter sequences in your datasets and confirm the expected sequence orientations. Report the commands you used, the reasoning behind them, and how you confirmed the adapter sequences.

-   Cco_com123_EO_6cm_1_1.fastq.gz : 15.8% of reads (R1) were trimmed.

-   Cco_com123_EO_6cm_1_2.fastq.gz : 16.3% of reads (R2) were trimmed.

-   Crh_rhy116_EO_adult_3_1.fastq.gz : 13.1% of reads (R1) were trimmed.

-   Crh_rhy116_EO_adult_3_2.fastq.gz : 13.7% of reads (R2) were trimmed.

When we switch adapter and file pairings (R1 adapter with R2 file) we find 0 matches in the file. However, maintaining what we now know is the correct pairing yields many matches, indicating that the pairing is correct.

Still, it should be noted that is is possible to get 0 with a match, assuming every adapter was partially cut off. However, this incredibly unlikely. Even more so when compared to the number of what would be non-adapter matches in the read of the other files. More so considering that adapters are intentionally selected, as they do not occur naturally. Basically, there is some chance that this method could be wrong, but it is incredibly unlikely. Keeping this in mind, we pass our sanity check.

Also, note the difference in proportions between these results and cutadapt is because here, we are searching for the *entire* adapter, which can often be cutoff and/or lost in sequencing.

```{bash, eval=FALSE}

$ zcat Cco_com123_EO_6cm_1_1.fastq.gz | grep -c AGATCGGAAGAGCACACGTCTGAACTCCAGTCA ## 147375
$ zcat Cco_com123_EO_6cm_1_2.fastq.gz | grep -c AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT ## 55585
$ zcat Crh_rhy116_EO_adult_3_1.fastq.gz | grep -c AGATCGGAAGAGCACACGTCTGAACTCCAGTCA ## 964952
$ zcat Crh_rhy116_EO_adult_3_2.fastq.gz | grep -c AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT ## 311694

## WHEN YOU SWITCH THE ADAPTERS TO WHAT WE NOW KNOW IS BACKWARDS, WE DO NOT FIND THEM IN THE FILE
$ zcat Cco_com123_EO_6cm_1_1.fastq.gz | grep -c AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT ## 0 
$ zcat Cco_com123_EO_6cm_1_2.fastq.gz | grep -c AGATCGGAAGAGCACACGTCTGAACTCCAGTCA ## 0
$ zcat Crh_rhy116_EO_adult_3_2.fastq.gz | grep -c AGATCGGAAGAGCACACGTCTGAACTCCAGTCA ## 0
$ zcat Crh_rhy116_EO_adult_3_1.fastq.gz | grep -c AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT ## 0 

```

7.  Use `Trimmomatic` to quality trim your reads. Specify the following, **in this order**:

    -   LEADING: quality of 3
    -   TRAILING: quality of 3
    -   SLIDING WINDOW: window size of 5 and required quality of 15
    -   MINLENGTH: 35 bases

    Be sure to output compressed files and clear out all intermediate files.

```{bash, eval=FALSE}
trimmomatic PE -threads 8 \
Cco_com123_EO_6cm_1_1_cut.fastq.gz Cco_com123_EO_6cm_1_2_cut.fastq.gz \
Cco_com123_EO_6cm_1_1_cut_paired.fastq.gz Cco_com123_EO_6cm_1_1_cut_unpaired.fastq.gz \
Cco_com123_EO_6cm_1_2_cut_paired.fastq.gz Cco_com123_EO_6cm_1_2_cut_unpaired.fastq.gz \
LEADING:3 TRAILING:3 SLIDINGWINDOW:5:15 MINLEN:35
```

```{eval = FALSE}
Quality encoding detected as phred33
Input Read Pairs: 3735980 Both Surviving: 3695585 (98.92%) Forward Only Surviving: 29316 (0.78%) Reverse Only Surviving: 9603 (0.26%) Dropped: 1476 (0.04%)
TrimmomaticPE: Completed successfully
```

```{bash, eval=FALSE}
trimmomatic PE -threads 8 \
Crh_rhy116_EO_adult_3_1_cut.fastq.gz Crh_rhy116_EO_adult_3_2_cut.fastq.gz \
Crh_rhy116_EO_adult_3_1_cut_paired.fastq.gz Crh_rhy116_EO_adult_3_1_cut_unpaired.fastq.gz \
Crh_rhy116_EO_adult_3_2_cut_paired.fastq.gz Crh_rhy116_EO_adult_3_2_cut_unpaired.fastq.gz \
LEADING:3 TRAILING:3 SLIDINGWINDOW:5:15 MINLEN:35
```

```{eval = FALSE}
Quality encoding detected as phred33
Input Read Pairs: 32594028 Both Surviving: 32425688 (99.48%) Forward Only Surviving: 111529 (0.34%) Reverse Only Surviving: 51935 (0.16%) Dropped: 4876 (0.01%)
TrimmomaticPE: Completed successfully
```

8.  Plot the trimmed read length distributions for both paired R1 and paired R2 reads (on the same plot - yes, you will have to use Python or R to plot this. See ICA4 from Bi621). You can produce 2 different plots for your 2 different RNA-seq samples. There are a number of ways you could possibly do this. One useful thing your plot should show, for example, is whether R1s are trimmed more extensively than R2s, or vice versa. Comment on whether you expect R1s and R2s to be adapter-trimmed at different rates and why.

[Include your plot and comment on R1/R2 adapter trimming]

```{R, eval=TRUE}

```

9.  Bonus - Run `FastQC` on your trimmed data. Comment on differences you observe between the trimmed and untrimmed data. Include any figures needed to support your conclusions.

[Include command, comments on differences, and plot/s]

```{bash, eval=FALSE}

```

## Part 3 â€“ Alignment and strand-specificity

10. Install additional software for alignment and counting of RNA-seq reads. In your QAA environment, use conda to install:
    -   Star
    -   Picard
    -   Samtools
    -   NumPy
    -   Matplotlib
    -   HTSeq

[Record details on how you installed these packages]

```{bash, eval=FALSE}
$ mamba install Star
$ mamba install Picard
$ mamba install Samtools
$ mamba install NumPy
$ mamba install Matplotlib
$ mamba install HTSeqs
```

11. Download the publicly available *Campylomormyrus compressirostris* genome fasta and gff file from [Dryad](https://datadryad.org/dataset/doi:10.5061/dryad.c59zw3rcj) and generate an alignment database from it. If the download fails, the files are available `/projects/bgmp/shared/Bi623/PS2/campylomormyrus.fasta`, `/projects/bgmp/shared/Bi623/PS2/campylomormyrus.gff`. Align the reads to your *C. compressirostris* database using a splice-aware aligner. Use the settings specified in PS8 from Bi621.

> [!IMPORTANT] You will need to use gene models to perform splice-aware alignment, see PS8 from Bi621. You may need to convert the gff file into a gtf file for this to work successfully.

[Record details on how you downloaded the genome, prepared the dataset for alignment, and commands for generating the alignment database and aligning reads]

```{bash, eval=FALSE}

```

12. Remove PCR duplicates using [Picard MarkDuplicates](https://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates). You may need to sort your reads with `samtools` before running Picard.

-   Use the following for running picard: picard MarkDuplicates INPUT=[FILE] OUTPUT=[FILE] METRICS_FILE=[FILENAME].metrics REMOVE_DUPLICATES=TRUE VALIDATION_STRINGENCY=LENIENT

```{bash, eval=FALSE}

```

13. Using your script from PS8 in Bi621, report the number of mapped and unmapped reads from each of your 2 SAM files post deduplication with picard. Make sure that your script is looking at the bitwise flag to determine if reads are primary or secondary mapping (update/fix your script if necessary).

[Include the number of mapped and unmapped reads from both same files]

14. Count deduplicated reads that map to features using `htseq-count`. You should run htseq-count twice: once with `--stranded=yes` and again with `--stranded=reverse`. Use default parameters otherwise. You may need to use the `-i` parameter for this run.

```{bash, eval=FALSE}

```

15. Demonstrate convincingly whether or not the data are from "strand-specific" RNA-Seq libraries **and** which `stranded=` parameter should you use for counting your reads for a future differential gene expression analyses. Include any commands/scripts used. Briefly describe your evidence, using quantitative statements (e.g. "I propose that these data are/are not strand-specific, because X% of the reads are y, as opposed to z."). This [kit](https://www.revvity.com/product/nex-rapid-dir-rna-seq-kit-2-0-8rxn-nova-5198-01) was used during library preparation. This [paper](https://academic.oup.com/bfg/article/19/5-6/339/5837822) may provide helpful information.

> [!TIP] Recall ICA4 from Bi621.

[Describe whether your reads are "string-specific", why you think they are, any evidence, and which stranded parameter is appropriate and why]

16. BONUS - Turn your commands from part 1 and 2 into a script with a loop going through your two SRA files

## Bonus (optional!)

Review the [publication](https://doi.org/10.1093/molbev/msae021) from PRJNA1005244 or the third chapter of the [thesis](https://canvas.uoregon.edu/courses/266187/files/22059308?module_item_id=5380118) for the PRJNA1005245 dataset. See if this information leads to any additional insight of your analysis.

[Add insights to the dataset]

## Upload your:

-   [ ] lab notebook
-   [ ] Talapas batch script/code
-   [ ] FastQC plots
-   [ ] counts files generated from htseq-count (in a folder would be nice; **only include the counts files that would be used in a future differential RNA-seq analysis: use the format Species_sample_tissue_age/size_sample#*readnumber_htseqcounts*[revORyes]stranded.txt**)
-   [ ] pdf report (see below; turn into both Github AND Canvas)
-   [ ] and any additional plots, code, or code output

to GitHub.

### Pdf report details

You should create a pdf file (using Rmarkdown) with a high-level report including:

-   [ ] all requested plots
-   [ ] answers to questions
-   [ ] mapped/unmapped read counts from PS8 script (in a nicely formatted table)
-   [ ] It should be named `QAA_report.pdf`
-   [ ] Include at the top level of your repo
-   [ ] ALSO, submit it to Canvas.

> [!TIP] You may need to install LaTeX to knit your rmarkdown into a pdf file. Run `tinytex::install_tinytex()` to install it on R.

The three parts of the assignment should be clearly labeled. Be sure to title and write a descriptive figure caption for each image/graph/table you present.

> [!TIP] Think about figure captions you've read and discussed in Journal Club. Find some good examples to model your captions on.
